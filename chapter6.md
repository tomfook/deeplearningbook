## Chapter 6 Deep Feedforward Networks

ディープ・フィードフォワード・ネットワーク、フィードフォワード・ニューラル・ネットワークもしくは多層パーセプトロン(MLPs)とも呼ばれる、は典型的なディープラーニングモデルである。
フィードフォワードネットワークの目的はある関数$f^*$を近似することである。
たとえば分類機であれば$y=f^*(\mathbf x)$は入力$\mathbf x$の分類$y$への写像である。
フィードフォワードネットワークは写像$\mathbf y=f(\mathbf x;\mathbf \theta)$を定義し、最も良い関数近似になるパラメータ$\mathbf \theta$の値を学習する。

これらのモデルが**フィードフォワード(feedforward)** と呼ばれるのは、$\mathbf x$により評価される関数を通して情報が中間的な計算$f$を通って最後に$\mathbf y$として出力されるためである。
モデルの出力をモデル自身に戻す**フィードバック(feedback)** 接続は存在しない。
フィードフォワード・ニューラル・ネットワークがフィードバック接続を含むよう拡張されるとき、それらはリカレント・ニューラル・ネットワークと呼ばれる。
これについてはchapter10で説明する。

フィードフォワード・ネットワークは機械学習の実務家にとって最も重要である。
これらはいくつもの重要な商用アプリケーションの基礎になっている。
たとえば写真の物体認識に用いられる畳み込みネットワークはフィードフォワード・ネットワークの一種である。
フィードフォワード・ネットワークは自然言語に適用されるリカレント・ネットワークの着想の基礎になっている。

フィードフォワード・ニューラル・ネットワークが**ネットワーク(network)** と呼ばれるのは、典型的には多くの異なる関数を繋げることによって表されるためである。
モデルは関数がどのように繋がっているかを表す有向非巡回グラフと関連付けられる。たとえば、３つの関数$f^{(1)},f^{(2)},f^{(3)}$があり、これらが鎖のように繋がって$f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$を構成しているとする。
これはニューラル・ネットワークで最もよく使われる構造である。
この場合において、$f^{(1)}$はネットワークの**第１層(first layer)** と呼ばれ、$f^{(2)}$は**第２層(second layer)** と呼ばれ、以下も同様である。
この鎖全体の長さがモデルの**深さ(depth)** を表す。
「ディープラーニング」という言葉はこの文脈で出てきた。
フィードフォワード・ネットワークの最後の層は**出力層(output layer)** と呼ばれる。
ニューラル・ネットワークの訓練の際、$f^*(x)$に適合するよう$f(x)$を操る。
訓練データはノイズを持つため、$f^*(x)$を近似する実現値として得られる。
それぞれの実現値$x$はラベル$y\approx f^*(x)$を伴う。
訓練データは出力層がそれぞれの$x$でするべきこと、すなわち$y$に近い値を出力することを直接に決定する。
学習アルゴリズムはこれらの層が望む値を出力する方法を決定しなければならないが、訓練データはそれぞれ個々の層が何をするべきかは教えてくれない。
その代わりに学習アルゴリズムはこれらの層をどう使えば$f^*$の近似を最もよく実現するかを決定する。
訓練データはそれぞれの層の出力を示さないためこれらは**隠れ層** と呼ばれる。

これらのネットワークが*ニューラル(neural)* と呼ばれるのは脳科学から緩くインスパイアされているためである。
典型的にはこれらの隠れ層はベクトル値を取る。
隠れ層の次元はモデルの**幅(width)** を決定する。
それぞれのベクトルの要素はニューロンと似た働きをすると解釈されることもある。
それぞれの層は一つのベクトルからベクトルへの関数であると考えるよりはむしろ、層が並列に働く多くのベクトルからスカラーへの関数という**単位(units)** によって構成されていると考えることもできる。
この単位はほかの単位からの入力を受け取り活性化関数を計算するニューロンに似ている。
ベクトル値をとる表現の多くの層という発想は脳科学によって得られた。
これらの表現を計算するために用いられる関数$f^{(i)}(\mathbf x)$の選択方法もまた、脳科学によるニューロンが計算する機能の観察により緩く導かれている。
しかし現代的なニューラル・ネットワークの研究は多くの数学的、工学的な方法論によって導かれており、ニューラル・ネットワークの目的は脳の完全なモデルを作ることではない。
フィードフォワード・ネットワークは統計的な汎化性能を達成するよう設計された関数近似機械と考えるのがベストであり、脳についての知識から洞察を得ることはあっても脳の機能をモデル化しようとしているわけではない。

フィードフォワード・ネットワークを理解するための一つの方法は線形モデルから始めて、どうやってその限界に打ち勝つかを考えることである。
線形モデル、たとえばロジスティック回帰や線形回帰、が魅力があるのはこれらが効率よくまた高い信頼性で適合し、閉じた表現で解けるかまたは凸最適化できるためである。
また線形モデルは線形関数に制限されるモデルキャパシティという明らかな欠点を持っているため、二つの入力変数の間の相互作用を学習することはできない。

線形モデルを拡張して$x$の非線形関数を表すために、我々は線形モデルを$x$そのものではなく、非線形変換$\phi(x)$により変換された入力に対して適用することができる。
同様に我々が5.7.2節で写像$\phi$を暗に使って非線形学習アルゴリズムを得るために使ったカーネルトリックを適用することができる。
我々は$\phi$が$x$の特徴を表現する集合か、もしくは$x$の新しい表現を与えるものであると考えることができる。

問題はどうやって写像$\phi$を選択するかである。

1. 一つの選択肢は非常に汎用的な$\phi$を選択することである。
  たとえばRBFカーネルに基づくカーネルマシンによって暗に使われる無限次元関数である。
  もし$\phi(x)$が十分高い次元を持つのであれば、我々は常に訓練データに対しては十分なキャパシティを持つことができるが、テストデータに対する汎化能力は悪いかもしれない。
  非常に一般的な特徴マッピングは局所平滑化の原則に基づくことが通常であり、発展的な問題を解くために事前知識をエンコードすることはない。
  
2. もう一つの選択肢は$\phi$を手動で設計することである。
  ディープラーニングが現れる前まではこの手法が支配的だった。
  これは音声認識やコンピュータビジョンといったそれぞれの領域に特化した専門家たちの人間の多大な労力を必要とする上に、この労力は異なる領域の間でほとんど共有できなかった。
  
3. ディープラーニングの戦略は$\phi$を学習するというものである。
  このアプローチでは我々のモデルは$y=f(x;\theta,w)=\phi(x;\theta)^\mathrm Tw$である。
  我々は広いクラスの関数群から$\phi$を学習するためのパラメータ$\theta$と、$\phi(x)$から出力を得るための写像$w$を持つ。
  これはディープ・フィードフォワード・ネットワークの一例であり、$\phi$は隠れ層を定義する。
  このアプローチは三つの中で唯一、学習問題の凸性を諦めている。
  しかしその利益は害を上回る。
  このアプローチでは表現を$\phi(x;\theta)$としてパラメータ化し、最も良い表現を得られる$\theta$を見つけるために最適化アルゴリズムを使う。
  もし非常に広い属から$\phi(x;\theta)$をとれば、このアプローチは非常に一般的であるという１つ目のアプローチの利益を手に入れられる。
  またディープラーニングは２つ目のアプローチの利点も得ることができる。
  人間の実践家はその知識をうまくいくような$\phi(x;\theta)$の属を設計することに翻訳することで汎化性能を高めることができる。
  これは人間の設計者が厳密に正しい関数を見つけるのではなく正しい関数群を見つけるだけでよいという利点がある。
  
特徴抽出によりモデルを改善するという一般原理は本章で説明するフィードフォワード・ネットワークについてだけではない。
それは本書で説明するディープラーニングのモデルへの適用すべてのテーマとして現れる。
フィードフォワード・ネットワークは$x$から$y$への決定論的写像をフィードバック接続なしで学習するためのこの原理の実用例である。
後で説明する他のモデルは確率的写像やフィードバック関数や一つのベクトル上の確率分布に対してこの原理を適用する。

まず我々はこの章をフィードフォワード・ネットワークのシンプルな例から始める。
次にフィードフォワード・ネットワークを動かすのに必要な設計項目の位置づけを行う。
フィードフォワード・ネットワークの訓練は線形モデルが持つ多くの設計項目を共有している。
すなわち最適化手法(オプティマイザ）、損失関数、出力の形式である。
次に勾配に基づく学習の基礎をおさらいする。
これはフィードフォワード・ネットワークに特有の設計項目と対決する。
フィードフォワード・ネットワークは隠れ層のコンセプトを導入したため、隠れ層の値を計算するための**活性化関数(activation functions)** の選択を必要とする。
我々はまたネットワーク構造の設計もしなければならない。
すなわちネットワークの層をどれだけ持つか、これらの層がどのようにそれぞれと接続されるべきか、それぞれの層の中で要素をどれだけ持つべきか、などである。
ディープ・ニューラル・ネットワークの学習には複雑な関数の勾配を計算する必要がある。
我々は**逆伝搬(back-propagation)** アルゴリズムを示し、その現代的な一般化が効率的に勾配を計算できることを示す。
最後に歴史的な展望を述べて終わる。

### 6.1 Example: Learning XOR

フィードフォワード・ネットワークのアイデアをより具体的にするために、我々は完全な関数としてのフィードフォワード・ネットワークを非常に単純なタスク、XOR関数の学習、から始める。

XOR関数とは二つのバイナリ値$x_1$と$x_2$の操作である。
これらのどちらかだけが1に等しいとき、XOR関数は1を返す。
そうでなければ0を返す。
XOR関数が学習したい対象$y=f^*(\mathbf x)$を定める。
我々のモデルは関数$y=f(\mathbf x;\mathbf \theta)$であり、我々の学習アルゴリズムは$\mathbf\theta$を調整して可能な限り$f$を$f^*$に似せる。

この単純な例では統計的な一般化を行わない。
我々のネットワークは厳密に$\mathbb X=\{[0,0]^\mathrm T,[0,1]^\mathrm T,[1,0]^\mathrm T,[1,1]^\mathrm T\}$上の４点を取るとする。
我々はネットワークをこれらの４点上で訓練する。
訓練集合上での当てはまりだけに取り組めばよい。

我々はこの問題を回帰問題として扱い、損失関数として平均二乗誤差を使うことができる。
我々は可能な限り損失関数を数学的に単純化した。
実際の問題では通常MSE(平均二乗誤差)はバイナリデータの損失関数としては不適切である。
より適切なアプローチについては6.2.2.2で述べる。

訓練データ全体で評価したMSE損失関数はeq(6.1)
$$
J(\theta)=\frac14\sum_{\mathbf x\in\mathbb X}(f^*(\mathbf x)-f(\mathbf x;\theta))^2
$$
である。

ここで我々はモデル$f(\mathbf x;\theta)$を選択しなければならない。
我々が線形モデルを選択したならば、$\theta$は$\mathbf w$と$b$から成り、eq(6.2)
$$
f(\mathbf x;\mathbf w,b)=\mathbf x^\mathrm T\mathbf w+b
$$
である。
我々は正規方程式を使うことで$J(\theta)$を$\mathbf w$と$b$について閉じた形で最小化できる。

正規方程式を解けば、$\mathbf w=\mathbf 0$と$b=\frac12$が得られる。
線形モデルの出力はすべての点で0.5になる。
なぜこのようになるのか？
図6.1はどのようにして線形モデルがXORの表現に失敗しているのかを表している。
この問題を解く一つの方法は線形モデルが解くことができるような異なる特徴空間に対してモデルを用いることである。

我々は単純な２つの要素を持つ１の隠れ層を持つ単純なフィードフォワード・ネットワークを導入する。
図6.2でのこのモデルの働きを見よ。




**図6.1** 
学習による表現としてXOR問題を解く。
太い数字でプロットされているのが学習した関数がそれぞれの点で出力した値。
（左図）元々の入力に適用された線形モデルがXOR関数を実行できていない。
$x_1=0$のとき、$x_2$が増えるとモデルの出力は増えなければならない。
$x_1=1$のとき、$x_2$が増えるとモデルの出力は減らなければならない。
線形モデルは$x_2$の係数$w_2$を固定しなければならない。
線形モデルは$x_2$の係数を変化させるのに$x_1$の値を使うことができずに問題を解くことができない。
（右図）
