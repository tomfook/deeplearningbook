## Chapter 6 Deep Feedforward Networks

ディープ・フィードフォワード・ネットワーク、フィードフォワード・ニューラル・ネットワークもしくは多層パーセプトロン(MLPs)とも呼ばれる、は典型的なディープラーニングモデルである。
フィードフォワードネットワークの目的はある関数$f^*$を近似することである。
たとえば分類機であれば$y=f^*(\mathbf x)$は入力$\mathbf x$の分類$y$への写像である。
フィードフォワードネットワークは写像$\mathbf y=f(\mathbf x;\mathbf \theta)$を定義し、最も良い関数近似になるパラメータ$\mathbf \theta$の値を学習する。

これらのモデルが**フィードフォワード(feedforward)** と呼ばれるのは、$\mathbf x$により評価される関数を通して情報が中間的な計算$f$を通って最後に$\mathbf y$として出力されるためである。
モデルの出力をモデル自身に戻す**フィードバック(feedback)** 接続は存在しない。
フィードフォワード・ニューラル・ネットワークがフィードバック接続を含むよう拡張されるとき、それらはリカレント・ニューラル・ネットワークと呼ばれる。
これについてはchapter10で説明する。

フィードフォワード・ネットワークは機械学習の実務家にとって最も重要である。
これらはいくつもの重要な商用アプリケーションの基礎になっている。
たとえば写真の物体認識に用いられる畳み込みネットワークはフィードフォワード・ネットワークの一種である。
フィードフォワード・ネットワークは自然言語に適用されるリカレント・ネットワークの着想の基礎になっている。

フィードフォワード・ニューラル・ネットワークが**ネットワーク(network)** と呼ばれるのは、典型的には多くの異なる関数を繋げることによって表されるためである。
モデルは関数がどのように繋がっているかを表す有向非巡回グラフと関連付けられる。たとえば、３つの関数$f^{(1)},f^{(2)},f^{(3)}$があり、これらが鎖のように繋がって$f(x)=f^{(3)}(f^{(2)}(f^{(1)}(x)))$を構成しているとする。
これはニューラル・ネットワークで最もよく使われる構造である。
この場合において、$f^{(1)}$はネットワークの**第１層(first layer)** と呼ばれ、$f^{(2)}$は**第２層(second layer)** と呼ばれ、以下も同様である。
この鎖全体の長さがモデルの**深さ(depth)** を表す。
「ディープラーニング」という言葉はこの文脈で出てきた。
フィードフォワード・ネットワークの最後の層は**出力層(output layer)** と呼ばれる。
ニューラル・ネットワークの訓練の際、$f^*(x)$に適合するよう$f(x)$を操る。
訓練データはノイズを持つため、$f^*(x)$を近似する実現値として得られる。
それぞれの実現値$x$はラベル$y\approx f^*(x)$を伴う。
訓練データは出力層がそれぞれの$x$でするべきこと、すなわち$y$に近い値を出力することを直接に決定する。
学習アルゴリズムはこれらの層が望む値を出力する方法を決定しなければならないが、訓練データはそれぞれ個々の層が何をするべきかは教えてくれない。
その代わりに学習アルゴリズムはこれらの層をどう使えば$f^*$の近似を最もよく実現するかを決定する。
訓練データはそれぞれの層の出力を示さないためこれらは**隠れ層** と呼ばれる。

これらのネットワークが*ニューラル(neural)* と呼ばれるのは脳科学から緩くインスパイアされているためである。
典型的にはこれらの隠れ層はベクトル値を取る。
隠れ層の次元はモデルの**幅(width)** を決定する。
それぞれのベクトルの要素はニューロンと似た働きをすると解釈されることもある。
それぞれの層は一つのベクトルからベクトルへの関数であると考えるよりはむしろ、層が並列に働く多くのベクトルからスカラーへの関数という**単位(units)** によって構成されていると考えることもできる。
この単位はほかの単位からの入力を受け取り活性化関数を計算するニューロンに似ている。
ベクトル値をとる表現の多くの層という発想は脳科学によって得られた。
これらの表現を計算するために用いられる関数$f^{(i)}(\mathbf x)$の選択方法もまた、脳科学によるニューロンが計算する機能の観察により緩く導かれている。
しかし現代的なニューラル・ネットワークの研究は多くの数学的、工学的な方法論によって導かれており、ニューラル・ネットワークの目的は脳の完全なモデルを作ることではない。
フィードフォワード・ネットワークは統計的な汎化性能を達成するよう設計された関数近似機械と考えるのがベストであり、脳についての知識から洞察を得ることはあっても脳の機能をモデル化しようとしているわけではない。

フィードフォワード・ネットワークを理解するための一つの方法は線形モデルから始めて、どうやってその限界に打ち勝つかを考えることである。
線形モデル、たとえばロジスティック回帰や線形回帰、が魅力があるのはこれらが効率よくまた高い信頼性で適合し、閉じた表現で解けるかまたは凸最適化できるためである。
また線形モデルは線形関数に制限されるモデルキャパシティという明らかな欠点を持っているため、二つの入力変数の間の相互作用を理解することはできない。

$x$の非線形関数を表すために線形モデルを拡張するために、我々は線形モデルを$x$そのものではなく、非線形変換$\phi(x)$により変換された入力に対して適用することができる。
同様に我々が5.7.2節で写像$\phi$を暗に使って非線形学習アルゴリズムを得るために使ったカーネルトリックを適用することができる。
我々は$\phi$が$x$の特徴を表現する集合か、もしくは$x$の新しい表現を与えるものであると考えることができる。

問題はどうやって写像$\phi$を選択するかである。

1. 一つの選択肢は非常に汎用的な$\phi$を選択することである。
  たとえばRBFカーネルに基づくカーネルマシンによって暗に使われる無限次元関数である。
  もし$\phi(x)$が十分高い次元を持つのであれば、我々は常に訓練データに対しては十分なキャパシティを持つことができるが、テストデータに対する汎化能力は悪いかもしれない。
  非常に一般的な特徴マッピングは局所平滑化の原則に基づくことが通常であり、発展的な問題を解くために事前知識をエンコードすることはない。
  
2. もう一つの選択肢は$\phi$を手動で設計することである。
  ディープラーニングが現れる前まではこの手法が支配的だった。
  これは音声認識やコンピュータビジョンといったそれぞれの領域に特化した専門家たちの人間の多大な労力を必要とする上に、この労力は異なる領域の間でほとんど共有できなかった。
  
3. ディープラーニングの戦略は$\phi$を学習するというものである。
  このアプローチでは我々のモデルは$y=f(x;\ehta,w)=\phi(x;\theta)^\mathrm Tw$である。
  我々は広いクラスの関数群から$\phi$を学習するためのパラメータ$\theta$と、$\phi(x)$から出力を得るための写像$w$を持つ。
  これはディープ・フィードフォワード・ネットワークの一例であり、$\phi$は隠れ層を定義する。
  このアプローチは三つの中で唯一、学習問題の凸性を諦めている。
  しかしその利益は害を上回る。
  このアプローチでは表現を$\phi(x;\theta)$としてパラメータ化し、最も良い表現を得られる$\theta$を見つけるために最適化アルゴリズムを使う。
  もし非常に広い属から$\phi(x;\theta)$をとれば、このアプローチは非常に一般的であるという１つ目のアプローチの利益を手に入れられる。
  またディープラーニングは２つ目のアプローチの利点も得ることができる。
  人間の実践家はその知識をうまくいくような$\phi(x;\theta)$の属を設計することに翻訳ことで汎化性能を高めることができる。
  これは人間の設計者が厳密に正しい関数を見つけるのではなく正しい関数群を見つけるだけでよいという利点がある。
